# WHAT I USED THE LLM FOR-

1.  a win checklist with estimated time for each task
2.  basic queries
3.  cross questioning and as a search engine
4.  frontend polishing
5.  boiler plate generation with wins
6.  debugging while deployment

---

# WHAT I DID MYSELF-

1.  decided on what to use for the assignment, starting with fastapi+next.js
2.  made the architechtural decisions of how the app should look and come together
3.  overviewed the llm code to make sure everything came together properly since I renamed a lot of files and routes
4.  checked docs(for example for gemini) consistently since llms give pre trained data which is often outdated

# LLM PROVIDER

1.  I went with gemini since it provides a good free tier (upto 1 million token generation a day)
2.  I went with the 2.5 flash model since the models beyond that often consume too many tokens making it rough on the limits
